{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-19 model for TrashBox dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX3FM-nqgbSQ"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, models, transforms\n",
        "import sys\n",
        "sys.path.insert(0, PATH_TO_MODULES_FOLDER)\n",
        "from dataloader import load_data\n",
        "from viz import show_confusion_mat, imshow, create_grid_for_mb\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnJvyPRWgbWc"
      },
      "source": [
        "class VGG(object):\n",
        "\n",
        "    def __init__(self, pretrained_model, device, num_classes=7, lr=0.0001, reg=0.0, dtype=np.float32, mode=\"ft_extract\"):\n",
        "        self.params = {}\n",
        "        self.reg = reg\n",
        "        self.dtype = dtype \n",
        "        self.model = pretrained_model\n",
        "        self.num_classes = num_classes\n",
        "        self.lr = lr\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.device = device\n",
        "        self.save_model_path = PATH_TO_SAVE_MODEL\n",
        "\n",
        "        self.set_parameter_requires_grad(mode)\n",
        "        num_features = self.model.classifier[6].in_features\n",
        "        features = list(self.model.classifier.children())[:-1]                  \n",
        "        features.extend([nn.Linear(num_features, num_classes).to(self.device)]) \n",
        "        self.model.classifier = nn.Sequential(*features)            \n",
        "                            \n",
        "    def set_parameter_requires_grad(self, mode):\n",
        "        if mode == \"ft_extract\":\n",
        "            for param in self.model.features.parameters():\n",
        "                param.requires_grad = False\n",
        "        elif mode == \"finetune_last\":\n",
        "            for param in self.model.features[:19].parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "                \n",
        "    def gather_optimizable_params(self):\n",
        "        params_to_optimize = []\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_optimize.append(param)\n",
        "\n",
        "        return params_to_optimize\n",
        "\n",
        "    \n",
        "    def train(self, dataloaders, dataset_sizes, num_epochs = 25):\n",
        "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "        best_acc = 0.0\n",
        "\n",
        "        params_to_optimize = self.gather_optimizable_params()\n",
        "        optimizer = optim.Adam(params_to_optimize, lr = self.lr)\n",
        "        exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "        for epoch in range(0, num_epochs):\n",
        "            print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
        "            print('-'*10)\n",
        "            \n",
        "            for mode in ['train', 'val']:\n",
        "                if mode == \"train\":\n",
        "                    exp_lr_scheduler.step()\n",
        "                    self.model.train()\n",
        "                else:\n",
        "                    self.model.eval() \n",
        "                    \n",
        "                total_loss = 0.0\n",
        "                total_correct = 0 \n",
        "\n",
        "                for inputs, labels in dataloaders[mode]:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    with torch.set_grad_enabled(mode == 'train'):\n",
        "                        outputs = self.model(inputs)\n",
        "                        _, y_preds = torch.max(outputs, 1)\n",
        "\n",
        "                        loss = self.loss_fn(outputs, labels)\n",
        "                \n",
        "                        if mode == \"train\":\n",
        "                            loss.backward() \n",
        "                            optimizer.step()\n",
        "                \n",
        "                    total_loss += loss.item() * inputs.size(0)\n",
        "                    total_correct += torch.sum(y_preds == labels.data)\n",
        "                \n",
        "                epoch_loss = total_loss / dataset_sizes[mode]\n",
        "                epoch_acc = total_correct.double() / dataset_sizes[mode]\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(mode, epoch_loss, epoch_acc))\n",
        "            \n",
        "                if mode == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "                    \n",
        "            print()\n",
        "\n",
        "        print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "        self.model.load_state_dict(best_model_wts)\n",
        "\n",
        "        torch.save(self.model.state_dict(), self.save_model_path)\n",
        "        \n",
        "        return self.model\n",
        "\n",
        "\n",
        "\n",
        "    def eval_model(self, dataloaders, mode = 'val'):\n",
        "        since = time.time()\n",
        "        avg_loss, avg_acc, total_loss, total_correct = 0,0,0,0\n",
        "        num_batches = len(dataloaders[mode])\n",
        "        mode_str = \"Validation\" if mode == 'val' else \"Test\"\n",
        "        \n",
        "        print(\"Evaluating model on {} set\".format(mode_str))\n",
        "        print('-' * 10)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(dataloaders[mode]):\n",
        "                if i % 100 == 0:\n",
        "                    print(\"\\r{} batch {}/{}\".format(mode_str, i, num_batches), end='', flush=True)\n",
        "                \n",
        "                self.model.train(False)\n",
        "                self.model.eval()\n",
        "\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                \n",
        "                outputs = self.model(inputs)\n",
        "                \n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                loss = self.loss_fn(outputs, labels)\n",
        "                \n",
        "                total_loss += loss.item() * inputs.size(0)\n",
        "                total_correct += torch.sum(preds == labels.data)\n",
        "            \n",
        "                del inputs, labels, outputs, preds\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "        avg_loss = total_loss / dataset_sizes[mode]\n",
        "        avg_acc = total_correct.double() / dataset_sizes[mode]\n",
        "            \n",
        "        elapsed_time = time.time() - since\n",
        "        print()\n",
        "        print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
        "        print(\"Average {} loss     : {:.4f}\".format(mode_str, avg_loss))\n",
        "        print(\"Average {} accuracy : {:.4f}\".format(mode_str, avg_acc))\n",
        "        print('-' * 10)\n",
        "\n",
        "                \n",
        "                \n",
        "    def load_model(self, path, train_mode = False):\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        if train_mode == False:\n",
        "            self.model.eval()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "\n",
        "    def visualize_model(self, dataloaders, num_images=16):\n",
        "        self.model.train(False)\n",
        "        self.model.eval()\n",
        "        \n",
        "        images_so_far = 0\n",
        "        file_path_base = PATH_TO_VISUALIZATION_FOLDER\n",
        "        confusion_matrix = torch.zeros(self.num_classes, self.num_classes)\n",
        "                                                   \n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(dataloaders['val']):\n",
        "                inputs, labels = data\n",
        "                size = inputs.size()[0]\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                outputs = self.model(inputs)                \n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                for t, p in zip(labels.view(-1), preds.view(-1)):\n",
        "                    confusion_matrix[t.long(), p.long()] += 1\n",
        "                    \n",
        "                create_grid_for_mb(i, inputs, num_images, class_names, preds, labels, file_path_base)\n",
        "\n",
        "       show_confusion_mat(confusion_matrix, self.num_classes, class_names, outfile=file_path_base + \"confusion_matrix_vgg19.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLbcN7qgbZB"
      },
      "source": [
        "pathname = PATH_TO_DATASET_SPLIT_FOLDER\n",
        "dataloaders, dataset_sizes, class_names = load_data(pathname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhM8t3Igbbj"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg19 = models.vgg19(pretrained=True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88A6JmbUgbdy"
      },
      "source": [
        "vgg_model = VGG(vgg19, device, num_classes=7, mode=\"finetune_all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEU4pkwNgbgR"
      },
      "source": [
        "vgg_model.train(dataloaders, dataset_sizes, num_epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaVbvW6Wgbi8"
      },
      "source": [
        "vgg_model.load_model(PATH_TO_THE_SAVED_MODEL, train_mode = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH7C90yygblQ"
      },
      "source": [
        "vgg_model.visualize_model(dataloaders, num_images=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1KxufdCgbnj"
      },
      "source": [
        "vgg_model.eval_model(dataloaders, mode = 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz3Lc865gb50"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}